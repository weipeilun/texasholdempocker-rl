# workflow params
num_predict_batch_process: 2
num_gen_winning_prob_cal_data_processes: 4
predict_batch_size: 9
game_loop_thread_multiple: 6
num_train_eval_process: 6
eval_task_num_games: 1000
update_model_bb_per_100_thres: 5.
historical_data_filename: data/history.txt
predict_batch_size_min: 1
predict_batch_size_max: 32
predict_batch_size_list: [1, 2, 4, 8, 16, 24]
predict_feature_size_list: [117, ]

# train process params
# notice: train data are doubled in order to train 'unknown cards' (opponents' card which can not be observed in MCTS simulation)
first_train_data_step: 500
train_per_step: 8
update_model_per_train_step: 400 # update_model_per_train_step * train_per_step = update_model_per_step
eval_model_per_step: 6000 # eval_model_per_step * train_per_step = eval_model_per_step
log_step_num: 200

# game params
small_blind: 25
big_blind: 50
# larger puct means more exploration, smaller puct means more exploitation
# 所以原则是：在保持模型和N的影响力的前提下（即结合场景调节对环境反馈的系数，这也让MCTS有效），尽量减小。1以减小num_mcts_simulation_per_step，即减少算力；2以减小模型badcase对后续训练数据的影响（对某一个类过高的直觉估计会导致过多执行该类，即在训练数据中N变大）。
# 如何判断puct的影响力有效：
# 1. 看N，每个类最重要保证一定的统计意义
# 2. 看R，每个类最终要拉到很接近的数值上
# 3. 看Q，每个类最终要符合环境的物理意义
num_mcts_simulation_per_step: 1200
mcts_c_puct: 0.1
# A large value of τ encourages more exploration by spending time visiting less-explored nodes, while a small value promotes exploitation by revisiting already explored nodes to gather more information.
mcts_tau: 0.5
mcts_dirichlet_noice_epsilon: 0.1  # 增加随机性，避免模型过于依赖历史数据。注意避免过大noise导致数据过脏，训练难以收敛
mcts_model_Q_epsilon: 0.2  # 当模型更有效后，适当调大这个值
mcts_choice_method: 'probability'  # choices: 'argmax', 'probability'
mcts_log_to_file: False
simulate_random_round_probs: [0.4, 0.15, 0.15, 0.15, 0.15]

# model params
batch_predict_model_type: 'TensorRT'  # choices: ['PyTorch', 'TensorRT']
model_param_dict:
    n_observation: 5
    n_actions: 4
    num_output_class: 12
    device: 'cuda:0'
    embedding_dim: 512
    positional_embedding_dim: 128
    transformer_head_dim: 64
    num_layers: 8
    historical_action_per_round: 3
    epsilon: 0.05
    epsilon_max: 0.8
    gamma: 0.9
    batch_size: 64
    base_learning_rate: 0.000005
    max_learning_rate: 0.00002
    step_size_up: 1000
    step_size_down: 5000
    l2_weight: 0.0
    num_bins: 10
    num_winning_prob_bins: 10
    num_acting_player_fields: 50
    save_train_data: True
    # 要保证用相对较新的数据学习，以确保模型在未在旧数据过拟合前朝向新数据收敛。
    transition_buffer_len: 800
    num_inference_per_step: 100   # show prediction result per steps
    num_data_print_per_inference: 5  # number of result to print per inference

# simulation params
simulation_recurrent_params:
  0:
    -
      -
        - 1
        - 0
        - False
      -
        - 1
        - 0
        - False
      -
        - 1
        - 0
        - True
      -
        - 4
        - 5
        - True
    - 98000
  1:
    -
      -
        - 1
        - 0
        - True
      -
        - 1
        - 0
        - True
      -
        - 2
        - 45
        - True
    - 97290
  2:
    -
      -
        - 1
        - 0
        - True
      -
        - 1
        - 0
        - False
      -
        - 1
        - 0
        - True
    - 45540
  3:
    -
      -
        - 1
        - 0
        - False
      -
        - 1
        - 0
        - True
    - 990

# checkpoints
model_init_checkpoint_path: models/best.pth
model_last_checkpoint_path: models/last.pth
model_eval_snapshot_path_format: models/eval_%s.pth
model_best_checkpoint_path: models/best.pth
model_workflow_tmp_checkpoint_path: models/workflow_tmp.pth
